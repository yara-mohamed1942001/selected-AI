{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "cCtZ-wrQQLB3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from sklearn.svm import SVC\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AREBBmswQYJ9",
    "outputId": "b82fcc14-0771-4d24-b7f7-2c3f23ad59ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "NVxgFCOAQY0F"
   },
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2)**2))\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = [self._predict(x) for x in X]\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        return accuracy_score(y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "t9OGYzMOQzKE"
   },
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, num_descriptors=10, resize_shape=(128, 128)):\n",
    "    images = []\n",
    "    features_glcm = []\n",
    "    features_fourier = []\n",
    "    labels = []\n",
    "    for label, class_folder in enumerate(os.listdir(folder)):\n",
    "        class_path = os.path.join(folder, class_folder)\n",
    "        for filename in os.listdir(class_path):\n",
    "            img = cv2.imread(os.path.join(class_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                # Resize the image to a fixed shape\n",
    "                img = cv2.resize(img, resize_shape)\n",
    "                images.append(img)\n",
    "                # Compute GLCM features\n",
    "                #glcm_features = compute_glcm_features(img)\n",
    "                #features_glcm.append(glcm_features)\n",
    "                labels.append(label)\n",
    "    # Check the length of all glcm features and crop them if necessary\n",
    "    #min_length = min(len(feature) for feature in features_glcm)\n",
    "    #features_glcm = [feature[:min_length] for feature in features_glcm]\n",
    "    return np.array(images), np.array(labels)\n",
    "x1, y1 = load_images_from_folder(\"/content/drive/MyDrive/archive2/Data/train\")\n",
    "x2, y2 = load_images_from_folder(\"/content/drive/MyDrive/archive2/Data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "vr7SzcPFQ4xm"
   },
   "outputs": [],
   "source": [
    "def get_block(images, num_blocks_x, num_blocks_y):\n",
    "\n",
    "    rows, cols = images.shape[1:]\n",
    "\n",
    "    block_size_rows = rows // num_blocks_x\n",
    "    block_size_cols = cols // num_blocks_y\n",
    "\n",
    "    images_blocks=[]\n",
    "\n",
    "    # Slice the image matrix into blocks\n",
    "\n",
    "    for image in (images):\n",
    "        sliced_blocks = []\n",
    "        for i in range(num_blocks_x):\n",
    "            for j in range(num_blocks_y):\n",
    "             block = image[i * block_size_rows: (i + 1) * block_size_rows, j * block_size_cols: (j + 1) * block_size_cols]\n",
    "             sliced_blocks.append(block)\n",
    "\n",
    "        images_blocks.append(sliced_blocks)\n",
    "    images_blocks=np.array(images_blocks)\n",
    "\n",
    "    return images_blocks\n",
    "\n",
    "def X_bar(img):\n",
    "\n",
    " XY=[]\n",
    " for i in range (len(img)):\n",
    "    feature_vector=[]\n",
    "    for block in range(len(img[i])):\n",
    "        x_bar=0\n",
    "        y_bar=0\n",
    "        denomenator=np.sum(img[i][block])\n",
    "\n",
    "        numerator1=0\n",
    "        for x in range(len(img[i][block])):\n",
    "            for y in range (len(img[i][block][x])):\n",
    "                numerator1=x*img[i][block][x][y]+numerator1\n",
    "\n",
    "        numerator2=0\n",
    "        for y in range(img.shape[3]):\n",
    "            for x in range (img.shape[2]):\n",
    "                numerator2=y*img[i][block][x][y]+numerator2\n",
    "\n",
    "        if denomenator != 0:\n",
    "           x_bar = numerator1 / denomenator\n",
    "           y_bar = numerator2 / denomenator\n",
    "        else:\n",
    "           x_bar = 0\n",
    "           y_bar = 0\n",
    "        feature_vector.append(x_bar)\n",
    "        feature_vector.append(y_bar)\n",
    "    feature_vector=np.array(feature_vector)\n",
    "\n",
    "    XY.append(feature_vector)\n",
    "\n",
    "\n",
    " XY=np.array(XY)\n",
    " return XY\n",
    "num_blocks_x =6\n",
    "num_blocks_y =6\n",
    "#X_cent_test=X_bar(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "40uldOS1R2eS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class AntColonyFeatureSelection:\n",
    "    def __init__(self, X, y, pheromone_init=0.1, alpha=1, beta=2, evaporation_rate=0.5, iterations=100, ants=10):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.num_features = X.shape[1]\n",
    "        self.pheromone = np.ones(self.num_features) * pheromone_init\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.evaporation_rate = evaporation_rate\n",
    "        self.iterations = iterations\n",
    "        self.ants = ants\n",
    "\n",
    "    def select_features(self, n_features):\n",
    "        best_subset = None\n",
    "        best_score = float('-inf')\n",
    "\n",
    "        for _ in range(self.iterations):\n",
    "            for ant in range(self.ants):\n",
    "                subset = self.construct_solution()\n",
    "                score = self.evaluate_subset(subset)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_subset = subset\n",
    "\n",
    "                self.update_pheromone(subset, score)\n",
    "\n",
    "            self.pheromone *= (1 - self.evaporation_rate)\n",
    "\n",
    "        # Select the best 'n_features' based on their scores\n",
    "        sorted_indices = sorted(range(len(best_subset)), key=lambda i: best_subset[i], reverse=True)\n",
    "        best_subset = sorted_indices[:n_features]\n",
    "\n",
    "        return best_subset\n",
    "\n",
    "\n",
    "    def construct_solution(self):\n",
    "        subset = []\n",
    "        remaining_features = list(range(self.num_features))\n",
    "\n",
    "        while remaining_features:\n",
    "            probabilities = self.calculate_probabilities(remaining_features)\n",
    "            probabilities /= np.sum(probabilities)  # Normalize probabilities\n",
    "            feature = np.random.choice(remaining_features, p=probabilities)\n",
    "            subset.append(feature)\n",
    "            remaining_features.remove(feature)\n",
    "\n",
    "        return subset\n",
    "\n",
    "    def calculate_probabilities(self, remaining_features):\n",
    "        probabilities = np.zeros(len(remaining_features))\n",
    "        total_pheromone = np.sum(self.pheromone[remaining_features])\n",
    "\n",
    "        if total_pheromone == 0:\n",
    "            probabilities[:] = 1 / len(remaining_features)\n",
    "        else:\n",
    "            for i, feature in enumerate(remaining_features):\n",
    "                probabilities[i] = (self.pheromone[feature] ** self.alpha) * ((1.0 / (total_pheromone)) ** self.beta) / total_pheromone\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def evaluate_subset(self, subset):\n",
    "        if len(subset) == 0:\n",
    "            return float('-inf')\n",
    "\n",
    "        knn = KNeighborsClassifier()\n",
    "        X_subset = self.X[:, subset]\n",
    "        knn.fit(X_subset, self.y)\n",
    "        y_pred = knn.predict(X_subset)\n",
    "        return accuracy_score(self.y, y_pred)\n",
    "\n",
    "    def update_pheromone(self, subset, score):\n",
    "        for feature in subset:\n",
    "            self.pheromone[feature] += score  # Here, you can use the score or any other metric related to the feature subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "HeuJzsZrR_D_"
   },
   "outputs": [],
   "source": [
    "#centroid features\n",
    "Xc = np.concatenate((x1, x2))\n",
    "y = np.concatenate((y1, y2))\n",
    "\n",
    "X_block=get_block(Xc,num_blocks_x, num_blocks_y)\n",
    "X_cent=X_bar(X_block)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cent, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caZ6XcynSPqc",
    "outputId": "5b8f6ad9-5a05-4542-e8a6-59d665927a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best subset: [3, 17, 19, 14, 5, 20, 37, 32, 52, 71, 2, 55, 36, 69, 39, 38, 43, 67, 65, 60, 6, 47, 46, 35, 22, 57, 51, 66, 0, 42, 58, 23, 50, 62, 28, 11, 8, 21, 4, 30]\n"
     ]
    }
   ],
   "source": [
    "aco = AntColonyFeatureSelection(X_cent, y)\n",
    "selected_features = aco.select_features(n_features=40)\n",
    "print(\"Best subset:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "C7Jqc4szSZHj"
   },
   "outputs": [],
   "source": [
    "# Reduce feature space based on selected features\n",
    "X_selected_train = X_train[:, selected_features]\n",
    "X_selected_test = X_test[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "q5yIknPFSZCL"
   },
   "outputs": [],
   "source": [
    "# Reshape the input data\n",
    "X_selected_train_flattened = X_selected_train.reshape(X_selected_train.shape[0], -1)\n",
    "X_selected_test_flattened = X_selected_test.reshape(X_selected_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsBZvsxuQAvh",
    "outputId": "3a16ca2b-2a22-46a2-ab7d-667662ad0fc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# Assuming X_selected_train_flattened contains your training data after feature selection\n",
    "\n",
    "\n",
    "n_components = min(X_selected_train_flattened.shape[1], len(np.unique(y_train)) - 1)\n",
    "lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "\n",
    "# Fit LDA to the training data\n",
    "lda.fit(X_selected_train_flattened, y_train)\n",
    "\n",
    "# Fit LDA to the training data and transform it\n",
    "X_reduced_train = lda.fit_transform(X_selected_train_flattened, y_train)  # Assuming y_train contains the training labels\n",
    "\n",
    "# Transform the test data using the fitted LDA\n",
    "X_reduced_test = lda.transform(X_selected_test_flattened)\n",
    "# Now, X_reduced_train and X_reduced_test contain the reduced feature representations\n",
    "clf = KNN(k=3)\n",
    "clf.fit(X_reduced_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = clf.predict(X_reduced_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mfLqX2STEMd",
    "outputId": "4156a48e-890b-4b7d-8d8c-d1afb818f784"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "class CustomLDA:\n",
    "    def __init__(self, n_components=None):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.num_features = X.shape[1]\n",
    "\n",
    "        # Compute class means\n",
    "        self.class_means = np.array([np.mean(X[y == c], axis=0) for c in self.classes])\n",
    "\n",
    "        # Compute within-class scatter matrix\n",
    "        within_class_scatter = np.zeros((self.num_features, self.num_features))\n",
    "        for c in self.classes:\n",
    "            class_data = X[y == c]\n",
    "            class_mean_diff = class_data - self.class_means[self.classes.searchsorted(c)]\n",
    "            within_class_scatter += np.dot(class_mean_diff.T, class_mean_diff)\n",
    "\n",
    "        # Compute between-class scatter matrix\n",
    "        overall_mean = np.mean(X, axis=0)\n",
    "        between_class_scatter = np.zeros((self.num_features, self.num_features))\n",
    "        for c in self.classes:\n",
    "            class_mean_diff = self.class_means[self.classes.searchsorted(c)] - overall_mean\n",
    "            between_class_scatter += len(X[y == c]) * np.outer(class_mean_diff, class_mean_diff)\n",
    "\n",
    "        # Solve the generalized eigenvalue problem\n",
    "        eigvals, eigvecs = np.linalg.eig(np.linalg.inv(within_class_scatter).dot(between_class_scatter))\n",
    "        eig_pairs = [(np.abs(eigvals[i]), eigvecs[:, i]) for i in range(len(eigvals))]\n",
    "        eig_pairs = sorted(eig_pairs, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Select top eigenvectors based on number of components\n",
    "        if self.n_components is not None:\n",
    "            eig_pairs = eig_pairs[:self.n_components]\n",
    "\n",
    "        # Compute transformation matrix\n",
    "        self.w_matrix = np.array([eig_pairs[i][1] for i in range(len(eig_pairs))])\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.dot(X, self.w_matrix.T)\n",
    "\n",
    "lda = CustomLDA(n_components=2)\n",
    "lda.fit(X_selected_train_flattened, y_train)\n",
    "X_reduced_train = lda.transform(X_selected_train_flattened)\n",
    "X_reduced_test = lda.transform(X_selected_test_flattened)\n",
    "clf = KNN(k=3)\n",
    "clf.fit(X_reduced_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "predictions = clf.predict(X_reduced_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
